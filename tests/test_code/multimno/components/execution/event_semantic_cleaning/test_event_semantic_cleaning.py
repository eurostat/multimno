from pyspark.testing.utils import assertDataFrameEqual

from multimno.core.configuration import parse_configuration
from multimno.core.data_objects.silver.silver_network_data_object import SilverNetworkDataObject
from multimno.core.data_objects.silver.silver_semantic_quality_metrics import SilverEventSemanticQualityMetrics
from multimno.core.data_objects.silver.silver_event_flagged_data_object import SilverEventFlaggedDataObject
from multimno.core.constants.columns import ColNames
from multimno.components.execution.event_semantic_cleaning.event_semantic_cleaning import SemanticCleaning

from tests.test_code.fixtures import spark_session as spark
from tests.test_code.multimno.components.execution.event_semantic_cleaning.aux_event_semantic_cleaning import (
    expected_events,
    expected_metrics,
    set_input_data,
)
from tests.test_code.test_common import TEST_RESOURCES_PATH, TEST_GENERAL_CONFIG_PATH
from tests.test_code.test_utils import setup_test_data_dir, teardown_test_data_dir


fixtures = [spark, expected_metrics, expected_events]


def setup_function():
    setup_test_data_dir()


def teardown_function():
    teardown_test_data_dir()


def test_semantic_cleaning(spark, expected_events, expected_metrics):
    """
    DESCRIPTION:
        Test shall execute the SemanticCleaning component with a dataframe that has at least one type of all error
        flags.

    INPUT:
        Test Configs:
            general: tests/test_resources/config/general_config.ini
            component: tests/test_resources/config/event_semantic_cleaning/testing_event_semantic_cleaning.ini
        Input Data:
            event_data_silver_deduplicated: /opt/testing_data/..., generated by aux_event_semantic_cleaning.set_input_data

    EXPECTED OUTPUT:
        event_data_silver_flagged: (fixture) aux_event_semantic_cleaning.expected_events
        event_device_semantic_quality_metrics: (fixture) aux_event_semantic_cleaning.expected_metrics

    STEPS:
        1.- Init the SemanticCleaning component with test configs.
        2.- Write input data in /opt/testing_data
        3.- Read expected data with SilverEventFlaggedDataObject class (fixture)
        4.- Read expected data with SilverEventSemanticQualityMetrics class (fixture)
        5.- Execute the SemanticCleaning component.
        6.- Read written data in /opt/testing_data with SilverEventFlaggedDataObject and SilverEventSemanticQualityMetrics classes.
        7.- Assert event DataFrames are equal.
        8.- Assert metrics DataFrames are equal.
    """
    # Setup

    # init configs and paths
    component_config_path = (
        f"{TEST_RESOURCES_PATH}/config/event/event_semantic_cleaning/testing_event_semantic_cleaning.ini"
    )
    config = parse_configuration(TEST_GENERAL_CONFIG_PATH, component_config_path)

    # init component class
    semantic_cleaning = SemanticCleaning(TEST_GENERAL_CONFIG_PATH, component_config_path)

    # create input data
    set_input_data(spark, config)

    # Expected (defined as fixture)

    # Execution
    semantic_cleaning.execute()

    # Assertion
    # read from test data output
    output_events_data_object = semantic_cleaning.output_data_objects[SilverEventFlaggedDataObject.ID]
    output_events_data_object.read()

    output_metrics_data_object = semantic_cleaning.output_data_objects[SilverEventSemanticQualityMetrics.ID]
    output_metrics_data_object.read()

    assertDataFrameEqual(output_events_data_object.df, expected_events)

    assertDataFrameEqual(
        output_metrics_data_object.df.drop(ColNames.result_timestamp), expected_metrics.drop(ColNames.result_timestamp)
    )
