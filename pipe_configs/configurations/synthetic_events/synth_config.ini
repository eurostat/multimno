# Synthetic data generator configuration file
[Spark]
# parameters in this section are passed to Spark except session_name 
session_name = SyntheticSession


[SyntheticEvents]
  seed = 999
  n_agents = 10
  n_events_per_agent = 15
  n_partitions = 4
  timestamp_generator_type = equal_gaps
  timestamp_format = "%Y-%m-%dT%H:%M:%S" 
  starting_timestamp = "2023-01-01T00:00:00"
  ending_timestamp = "2023-01-05T00:00:00"
  location_generator_type = random_cell_id # Valid options: random_cell_id, random_lat_lon
  # Needed if location_generator_type=random_cell_id:
  cell_id_min = 1
  cell_id_max = 9999
  # Needed if location_generator_type=random_lat_lon:
  latitude_min = 31.4567
  latitude_max = 32.789
  longitude_min = 45.4567
  longitude_max = 46.789
  #
  mcc = 154
  # Synthetic error generation options
  do_error_generation = True
  null_row_probability = 0.1
  data_type_error_probability = 0.1
  out_of_bounds_probability = 0.1
  max_ratio_of_mandatory_columns_to_generate_as_null = 0.5
  sort_output = True
  #
  output_records_path = /opt/dev/sample_data/lakehouse/bronze/mno_events/20230101

