# Synthetic data generator configuration file
[Logging]
level = INFO
format= %(asctime)-20s %(message)s
datefmt = %y-%m-%d %H:%M:%S

[SyntheticEventsGenerator]
  random_cell_id = True
  seed = 999
  n_agents = 50
  n_events_per_agent = 100
  n_partitions = 4
  timestamp_generator_type = equal_gaps
  timestamp_format = "%Y-%m-%d %H:%M:%S" 
  starting_timestamp = "2022-01-01 00:00:00"
  ending_timestamp = "2022-04-01 00:00:00"
  location_generator_type = random_cell_id
  cell_id_min = 1
  cell_id_max = 9999
  mcc = 154
  output_records_path = /opt/dev/sample_data/synth_generated

[SyntheticErrorsGenerator]
  starting_timestamp = ${SyntheticEventsGenerator:starting_timestamp}
  ending_timestamp = ${SyntheticEventsGenerator:ending_timestamp}
  timestamp_format = ${SyntheticEventsGenerator:timestamp_format}
  null_row_probability = 0.1
  data_type_error_probability = 0.1
  out_of_bounds_probability = 0.1
  max_ratio_of_mandatory_columns_to_generate_as_null = 0.5
  seed = ${SyntheticEventsGenerator:seed}
  error_generator_input_path = ${SyntheticEventsGenerator:output_records_path}
  error_generator_output_path = /opt/dev/sample_data/synth_errors
  output_file_format = csv
  sort_output = True

[Spark]
  sedona_enabled = False
  spark.driver.host = localhost
  spark.driver.memory = 4g
  spark.driver.cores = 2
  session_name = MultiMNO-test
  spark.master = local[*]
  spark.eventLog.enabled = false
  spark.eventLog.dir = /opt/spark/spark-events
  spark.history.fs.logDirectory = opt/spark/spark-events


