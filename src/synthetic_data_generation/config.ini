# Synthetic data generator configuration file
[Logging]
level = INFO
format= %(asctime)-20s %(message)s
datefmt = %y-%m-%d %H:%M:%S

[SyntheticEventsGenerator]
  equal_gaps = True
  random_cell_id = True
  seed = 999
  n_agents = 1000
  n_events_per_agent = 1000
  n_partitions = 4
  timestamp_generator_type = equal_gaps
  timestamp_format = "%Y-%m-%d %H:%M:%S" 
  starting_timestamp = "2022-01-01 00:00:00"
  ending_timestamp = "2022-06-01 00:00:00"
  location_generator_type = random_cell_id
  cell_id_min = 1
  cell_id_max = 9999
  mcc = 9
  output_records_path = /opt/dev/sample_data/synth_generated

[SyntheticErrorsGenerator]
  starting_timestamp = ${SyntheticEventsGenerator:starting_timestamp}
  ending_timestamp = ${SyntheticEventsGenerator:ending_timestamp}
  timestamp_format = ${SyntheticEventsGenerator:timestamp_format}
  null_row_probability = 0.2
  data_type_error_probability = 0.2
  out_of_bounds_probability = 0.2
  max_ratio_of_mandatory_columns_to_generate_as_null = 0.5
  seed = ${SyntheticEventsGenerator:seed}
  error_generator_input_path = ${SyntheticEventsGenerator:output_records_path}
  error_generator_output_path = /opt/dev/sample_data/synth_errors
  output_file_format = csv
  sort_output = True

[Spark]
  spark.driver.host = localhost
  spark.driver.memory = 8g
  spark.driver.cores = 4
  session_name = MultiMNO-test
  spark.master = local[*]
  spark.eventLog.enabled = false


; "spark.executor.memory": "8g",
; "spark.eventLog.enabled": "true",  
;   "spark.eventLog.dir": "/opt/spark/spark-events",
;   "spark.history.fs.logDirectory": "/opt/spark/spark-events"  

